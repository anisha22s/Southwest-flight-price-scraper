## *EXECUTIVE SUMMARY*
The airline business is complicated and competitive, serving millions of passengers globally. Travel aggregators and booking services have grown in popularity in recent years, allowing customers to compare costs and locate the greatest ticket discounts through websites such as Google Flights. Southwest Airlines, a major US airline that has been operating for over 50 years, does not share their prices with these websites. In order to remain competitive in the market, the airline must constantly monitor and adjust its pricing strategies. To support Southwest Airlines' business decisions, this project involves collecting flight price data for four major different routes operated by Southwest Airlines: San Francisco to Las Vegas, San Francisco to Boston, San Francisco to Miami, and San Francisco to Los Angeles.
In order to structure this data for easy access and data analysis, I used web-scraping techniques to collect flight price data for Southwest Airlines. Selenium is a powerful web-scraping tool that can be used to automate browsing the web and extracting data. I used the Beautiful Soup library in Python to parse the data, which allowed me to extract specific data elements from the web pages. The data was stored in a MongoDB database. The database design was chosen due to its flexible querying which allows me to easily compare pricing trends across the four different routes. The dataset includes web-scraping time, the date, the price, and the route and is sorted in time series order for easier observation.
The resulting dataset can be used to make significant decisions on pricing strategies by monitoring price trends for each route and making decisions regarding resource allocation and route planning. Furthermore, frequent Southwest passengers may use the web scraping code to track flight pricing and make sensible choices about when to book.

## *BACKGROUND, CONTENT, AND DOMAIN KNOWLEDGE*
The airline business is complicated and competitive, serving millions of passengers globally. One such search engine tool ‘Google Flights’ allows for travelers to directly book tickets with the airline cutting the middle agent. Additionally, it relies on its own predictive models and distribution systems which offer unique features such as best prices, best times to book, inclusive baggage costs, and more. Southwest Airlines is a low-cost carrier with a reputation for providing affordable flights. However, it is currently one of the only domestic airlines in the U.S. that does not allow Google Flights to show flight prices. As one of the most popular airlines in the US for domestic travel, Southwest misses out on a large percentage of potential customers by not being part of the Google flights ecosystem. Pricing strategies are important in the airline industry, where customers are price-sensitive and choose their flights based on ticket prices. Therefore, it is essential for airlines to gather pricing data in order to adjust their pricing strategies, increase revenue, and stay competitive in the market.

## *DATA, PROCESS, DESIGN, AND REPRESENTATION*
To collect the flight price data for Southwest Airlines, I utilized web-scraping techniques, including Selenium, to extract pricing information from the Southwest Airlines website. Selenium is a powerful web-scraping tool that can be used to automate browsing the web and extracting data. As compared to other methods, Selenium is easier to implement and mimics human behavior quite well. I used the Beautiful Soup library in Python to parse the data, which allowed us to extract specific data elements from the web pages.
The data was stored in a MongoDB database. The database design was chosen due to its flexible querying, which is important when dealing with large datasets. It also allows for easy scaling, which is important as the dataset grows over time. The data was structured in a way that allows us to easily compare pricing trends across the four different routes. Each row in the dataset represents a single day's price for a specific route. The dataset includes web-scraping time, the date, the price, and the route. In addition, data in the database is sorted in time series order for easier observation.
The followings are the interpretation of web-scraping routines and some explanations of the dataset and code:

a. Login Simulation & Low Fare Calendar (Headless Login)
First, the script sets up the login credentials and the headers to make the request look like it's coming from a real browser. Then, it navigates to the Southwest Airlines website using Chrome options to run headlessly. The page is then navigated to the My Account page, where the user's profile page is shown. After logging into the page, the script then navigates to the low-fare calendar page, and the HTML of the page is written to a file named "low_fare_calendar_page.html". The Chrome driver is then quit, and the script terminates.

b. Scrape Flight Prices
The following is a Python script that uses Selenium to scrape flight prices from the Southwest Airlines website. The script uses Chrome web driver and navigates through the website to download the HTML pages for a set of specific flight routes and departure dates. The main function of the script is scrape_flight_prices(), which calls two helper functions to initialize the driver and get the next 6 months. The scrape() function is where the main process of web scraping occurs. It sets the parameters for web scraping, including the trip type, number of passengers, departure airport, arrival airports, and return month. Then, it initializes the Chrome driver and gets the list for the next 6 months. The six-month list is used to loop through each month to download the corresponding HTML page for each arrival airport. For each arrival airport, the script loops through each month in six months and constructs the URL for the low-fare calendar page on the Southwest Airlines website. It then navigates to the page, waits for it to load, and downloads the HTML page for the corresponding month and arrival airport. The HTML page is saved to a local file with a naming convention that includes the departure airport, arrival airport, and departure month. The filenames list is used to store the names of the downloaded files. Finally, the function quits the driver and prints a message indicating that the web scraping is completed.
To run the script, simply call the scrape_flight_prices() function. The output will be the downloaded HTML files for each specified flight route and departure month.

c. Parsing
The following code uses the BeautifulSoup library to parse the HTML files and extract the flight prices for each departure month and arrival airport. The main function of the script is parsing(), which loops through the downloaded files and parses each file using BeautifulSoup. For each file, the function checks the prefix of the file name to determine the arrival airport and stores the parsed soup object in a corresponding global variable. Finally, the parsed soup object is stored in the corresponding global variable. Simply call the parsing() function after running the scrape_flight_prices() function. 

d. Regular Web Scraping - Parse out all flight information
The function ‘flight_price_tables()’ collects and structures data on the prices of flights on four major routes operated by Southwest Airlines: San Francisco to Las Vegas, San Francisco to Boston, San Francisco to Miami, and San Francisco to Los Angeles. Within the function, there are two helper functions:
● get_next_month(): This function is used to get the next month of the current month. It
first retrieves the current date and then calculates the month of the next month by adding 32 days to the first day of the current month. The month of the next month is then returned as an integer.
● get_trip_names(): This function is used to scrape the names of the four routes from the Southwest Airlines website. It first retrieves the HTML source code for each route's web page and then uses the Beautiful Soup library to parse the HTML code and extract the route name. If the anti-scraping mechanism of the website is triggered, this function will use a pre-set manual name instead.
The function collects flight price data for each month and day of a route, using an empty list of trip_dfs to hold the data for each trip, and a list of soups to hold the HTML source code for each route's web page. If data is found, the function constructs a dictionary named record that holds the Date and Price information for each day, which is then appended to the records list. After all the data for a specific route has been collected, the function constructs a final Pandas DataFrame for that route by concatenating all the individual DataFrames, which is then appended to the trip_dfs list. The function then defines a dictionary named result that maps the route name to its corresponding DataFrame and prints out each data frame in the result.

e. Insert into MongoDB
The following code defines a function called insert_data, which inserts the data scraped from Southwest Airlines' website into a MongoDB database. The function starts by creating a database called "final_project" and a collection called "flight_price" in that database. If the collection already exists, it drops it to prevent re-writing. The function then creates a dictionary called a result that contains the four data frames created in the previous function flight_price_tables. It loops through this dictionary and inserts each data frame as a set of records into the "flight_price" collection. If the insertion is successful, it prints a message indicating which trip records were inserted successfully. If thecollection already exists, it prints a message indicating that.
  


## *RISKS*
When using web-scraping techniques such as Selenium, the code sometimes may trigger Southwest Airlines' anti-scraping mechanism, which can result in missing data for a certain month, or even cause unexpected errors in certain code blocks in the project.

## *CONCLUSION*
In conclusion, the flight price data collection and management project for Southwest Airlines has resulted in a valuable dataset that can be used to make informed pricing decisions and gain insights into consumer behavior. The resulting dataset can be used to make significant decisions regarding pricing strategies and remain competitive in the market. I used web-scraping techniques to collect the data and stored it in a MongoDB database. The use of MongoDB provides several advantages over traditional SQL databases. This project showcases the importance of designing data management systems that add value to the business problem at hand.
